{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Classification\n",
    "\n",
    "Following the binary classifier, you can also easily implement a multi-category classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Review) Logistic Regression\n",
    "\n",
    "### Hypothesis\n",
    "\n",
    "$$\n",
    "{H(X)} = {1 \\over {1+ e^{-XW}}}\n",
    "$$\n",
    "\n",
    "### Cost Function\n",
    "\n",
    "$$\n",
    "Cost(W) = {1 \\over m} {\\sum_{i=1}^m c(H(x_{i}), y_{i})}\n",
    "$$\n",
    "\n",
    "### Cross Entropy in Logistic Classification\n",
    "\n",
    "$$\n",
    "c(H(x), y) = \\begin{cases}-log(H(x)) : y=1 \\\\ -log(1-H(x)) : y=0\\end{cases} \n",
    "= -y log(H(x)) - (1-y) log(1-H(x))\n",
    "$$\n",
    "\n",
    "### Minimizing Cost\n",
    "\n",
    "$$\n",
    "W_{new} = W_{old} - \\alpha {\\partial \\over {\\partial W}} Cost(W)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Classification\n",
    "\n",
    "### Softmax Function (Hypothesis)\n",
    "\n",
    "$$\n",
    "S(y_{i}) = {{e^{y_i}} \\over {\\sum_{j=1}^n e^{y_{j}}}} \\\\\n",
    "\\\\\n",
    "n: Number\\ of\\ classes \\\\\n",
    "\\\\\n",
    "i: i\\ class\n",
    "$$\n",
    "\n",
    "### Cost Function\n",
    "\n",
    "$$\n",
    "Cost(W) = {1 \\over m} {\\sum_{i=1}^m D(S(X_{i}W + b),L_{i})} \\\\\n",
    "\\\\\n",
    "m: Number\\ of\\ instances \\\\\n",
    "\\\\\n",
    "i: i\\ instance\n",
    "$$\n",
    "\n",
    "### Cross Entropy in Multinomial Classification\n",
    "\n",
    "$$\n",
    "D(S, L) = - \\sum_{j=1}^n L_{j} log(S(y_{j})) \\\\\n",
    "\\\\\n",
    "n: Number\\ of\\ classes \\\\\n",
    "\\\\\n",
    "j: j\\ class\n",
    "$$\n",
    "\n",
    "### Minimizing Cost\n",
    "\n",
    "$$\n",
    "W_{new} = W_{old} - \\alpha {\\partial \\over {\\partial W}} Cost(W)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow Version: %s\" % (tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1, 2, 1, 1],\n",
    "          [2, 1, 3, 2],\n",
    "          [3, 1, 3, 4],\n",
    "          [4, 1, 5, 5],\n",
    "          [1, 7, 5, 5],\n",
    "          [1, 2, 5, 6],\n",
    "          [1, 6, 6, 6],\n",
    "          [1, 7, 7, 7]]\n",
    "\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "\n",
    "x_data = np.array(x_data, dtype=np.float32)\n",
    "y_data = np.array(y_data, dtype=np.float32)\n",
    "\n",
    "nb_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Weights: \n",
      " [[-0.10099822  0.6847899   1.6258513 ]\n",
      " [ 0.88112587 -0.63692456 -0.1427695 ]\n",
      " [ 0.82411087 -0.91326994 -0.4510184 ]\n",
      " [ 0.58053356  1.3066356  -0.60428965]] \n",
      "\n",
      "# Bias: \n",
      " [ 0.38414612 -0.6159301  -0.5453214 ]\n"
     ]
    }
   ],
   "source": [
    "# Weights\n",
    "tf.random.set_seed(2020)\n",
    "W = tf.Variable(tf.random.normal([4, nb_classes], mean=0.0))\n",
    "b = tf.Variable(tf.random.normal([nb_classes], mean=0.0))\n",
    "\n",
    "print('# Weights: \\n', W.numpy(), '\\n\\n# Bias: \\n', b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> #0 \n",
      " Weights: \n",
      "[[-0.11553647  0.6918998   1.6332797 ]\n",
      " [ 0.8638605  -0.62458277 -0.13784593]\n",
      " [ 0.797113   -0.8949384  -0.44235206]\n",
      " [ 0.55236673  1.3261304  -0.5956176 ]] \n",
      " Bias: \n",
      "[ 0.37683368 -0.61232066 -0.5416184 ] \n",
      " cost: 5.2257767\n",
      "\n",
      ">>> #1000 \n",
      " Weights: \n",
      "[[-0.8411931   0.75385374  2.2969847 ]\n",
      " [-0.07680082 -0.16606328  0.34429583]\n",
      " [ 0.618117   -0.6086176  -0.54967654]\n",
      " [ 0.24572133  1.326133   -0.28897592]] \n",
      " Bias: \n",
      "[-0.13876517 -0.8163229   0.1779835 ] \n",
      " cost: 0.50721896\n",
      "\n",
      ">>> #2000 \n",
      " Weights: \n",
      "[[-1.1914808   0.80435884  2.5967705 ]\n",
      " [-0.14087628 -0.18363482  0.42594275]\n",
      " [ 0.8594195  -0.52478886 -0.8748073 ]\n",
      " [ 0.22371401  1.3248692  -0.26570395]] \n",
      " Bias: \n",
      "[-0.40732294 -0.9690039   0.59922254] \n",
      " cost: 0.43953097\n",
      "\n",
      ">>> #3000 \n",
      " Weights: \n",
      "[[-1.464515    0.8519873   2.8221765 ]\n",
      " [-0.18783872 -0.19453     0.48380077]\n",
      " [ 1.0863445  -0.49375    -1.1327715 ]\n",
      " [ 0.16596384  1.3500665  -0.23314708]] \n",
      " Bias: \n",
      "[-0.63186496 -1.08178     0.9365396 ] \n",
      " cost: 0.39596182\n",
      "\n",
      ">>> #4000 \n",
      " Weights: \n",
      "[[-1.697922    0.9001363   3.0074346 ]\n",
      " [-0.22953543 -0.20061918  0.5315868 ]\n",
      " [ 1.3032706  -0.4934833  -1.3499686 ]\n",
      " [ 0.09487277  1.3891125  -0.2010959 ]] \n",
      " Bias: \n",
      "[-0.83245873 -1.1711738   1.226527  ] \n",
      " cost: 0.36297297\n",
      "\n",
      ">>> #5000 \n",
      " Weights: \n",
      "[[-1.9057775   0.9478083   3.1676147 ]\n",
      " [-0.26796636 -0.20388351  0.57328254]\n",
      " [ 1.5109538  -0.5109507  -1.5401874 ]\n",
      " [ 0.01810047  1.4356134  -0.17081594]] \n",
      " Bias: \n",
      "[-1.0164189 -1.2455534  1.4848666] \n",
      " cost: 0.33603936\n",
      "\n",
      ">>> #6000 \n",
      " Weights: \n",
      "[[-2.0948424   0.9941726   3.3103127 ]\n",
      " [-0.3038853  -0.20546497  0.6107832 ]\n",
      " [ 1.7097456  -0.53860354 -1.7113296 ]\n",
      " [-0.06074882  1.485766   -0.1421119 ]] \n",
      " Bias: \n",
      "[-1.1872404 -1.3096143  1.7197511] \n",
      " cost: 0.3131696\n",
      "\n",
      ">>> #7000 \n",
      " Weights: \n",
      "[[-2.2689846   1.0387573   3.4398637 ]\n",
      " [-0.33769488 -0.20603302  0.645161  ]\n",
      " [ 1.8999859  -0.5720022  -1.8681755 ]\n",
      " [-0.13977788  1.5373282  -0.11464822]] \n",
      " Bias: \n",
      "[-1.3469772 -1.3662182  1.9360921] \n",
      " cost: 0.29330796\n",
      "\n",
      ">>> #8000 \n",
      " Weights: \n",
      "[[-2.4307153   1.0813508   3.5589974 ]\n",
      " [-0.3696618  -0.2059924   0.67708796]\n",
      " [ 2.0820625  -0.60849404 -2.0137668 ]\n",
      " [-0.217931    1.5890023  -0.08818024]] \n",
      " Bias: \n",
      "[-1.4970391 -1.417211   2.1371472] \n",
      " cost: 0.2758096\n",
      "\n",
      ">>> #9000 \n",
      " Weights: \n",
      "[[-2.5818226   1.1218913   3.6695557 ]\n",
      " [-0.39999598 -0.20558535  0.70701504]\n",
      " [ 2.2564096  -0.64648116 -2.1501348 ]\n",
      " [-0.29460648  1.6400516  -0.06255731]] \n",
      " Bias: \n",
      "[-1.6384954 -1.4638423  2.325234 ] \n",
      " cost: 0.26023802\n",
      "\n",
      ">>> #10000 \n",
      " Weights: \n",
      "[[-2.7236586   1.1604131   3.772864  ]\n",
      " [-0.4288627  -0.20496319  0.7352611 ]\n",
      " [ 2.4234724  -0.6849797  -2.278707  ]\n",
      " [-0.36947724  1.6900569  -0.03769292]] \n",
      " Bias: \n",
      "[-1.7722151 -1.5069835  2.5020947] \n",
      " cost: 0.24627577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Learning Rate\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Softmax Function\n",
    "def softmax(X):\n",
    "    sm = tf.nn.softmax(tf.matmul(x_data, W) + b)\n",
    "    return sm\n",
    "\n",
    "# Training\n",
    "for i in range(10000+1):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        sm = softmax(x_data)\n",
    "        cost = tf.reduce_mean(-tf.reduce_sum(y_data*tf.math.log(sm), axis=1))        \n",
    "        W_grad, b_grad = tape.gradient(cost, [W, b])\n",
    "                \n",
    "        W.assign_sub(learning_rate * W_grad)\n",
    "        b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(\">>> #%s \\n Weights: \\n%s \\n Bias: \\n%s \\n cost: %s\\n\" % (i, W.numpy(), b.numpy(), cost.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "predicted = tf.argmax(softmax(x_data), axis=1)\n",
    "real = tf.argmax(y_data, axis=1)\n",
    "\n",
    "def acc(predicted, real):\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, real), dtype=tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "accuracy = acc(predicted, real).numpy()\n",
    "print(\"Accuracy: %s\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real.numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
